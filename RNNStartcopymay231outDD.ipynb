{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ outputprobs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m154\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m66,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm (\u001b[38;5;33mBatchNormalization\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m154\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ outputprobs (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m154\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,585</span> (264.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,585\u001b[0m (264.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,073</span> (262.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,073\u001b[0m (262.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.1215 - custom_cat: 1.0078 - loss: 1.7497 - val_accuracy: 0.1373 - val_custom_cat: 0.9972 - val_loss: 0.9150\n",
      "Epoch 2/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1375 - custom_cat: 0.9974 - loss: 0.7777 - val_accuracy: 0.1349 - val_custom_cat: 0.9955 - val_loss: 0.8587\n",
      "Epoch 3/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1383 - custom_cat: 0.9970 - loss: 0.7669 - val_accuracy: 0.1394 - val_custom_cat: 0.9972 - val_loss: 0.8090\n",
      "Epoch 4/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1390 - custom_cat: 0.9976 - loss: 0.7685 - val_accuracy: 0.1399 - val_custom_cat: 0.9967 - val_loss: 0.7767\n",
      "Epoch 5/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1393 - custom_cat: 0.9978 - loss: 0.7621 - val_accuracy: 0.1391 - val_custom_cat: 0.9994 - val_loss: 0.7815\n",
      "Epoch 6/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1392 - custom_cat: 0.9978 - loss: 0.7610 - val_accuracy: 0.1386 - val_custom_cat: 0.9952 - val_loss: 0.7735\n",
      "Epoch 7/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1393 - custom_cat: 0.9975 - loss: 0.7625 - val_accuracy: 0.1405 - val_custom_cat: 0.9950 - val_loss: 0.7782\n",
      "Epoch 8/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1395 - custom_cat: 0.9977 - loss: 0.7612 - val_accuracy: 0.1396 - val_custom_cat: 0.9916 - val_loss: 0.7972\n",
      "Epoch 9/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1397 - custom_cat: 0.9979 - loss: 0.7741 - val_accuracy: 0.1394 - val_custom_cat: 0.9973 - val_loss: 0.7667\n",
      "Epoch 10/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1405 - custom_cat: 0.9983 - loss: 0.7621 - val_accuracy: 0.1412 - val_custom_cat: 0.9957 - val_loss: 0.7583\n",
      "Epoch 11/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1412 - custom_cat: 0.9980 - loss: 0.7585 - val_accuracy: 0.1406 - val_custom_cat: 1.0050 - val_loss: 0.8263\n",
      "Epoch 12/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1409 - custom_cat: 0.9979 - loss: 0.7621 - val_accuracy: 0.1403 - val_custom_cat: 0.9987 - val_loss: 0.7629\n",
      "Epoch 13/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1404 - custom_cat: 0.9978 - loss: 0.7572 - val_accuracy: 0.1402 - val_custom_cat: 0.9933 - val_loss: 0.8013\n",
      "Epoch 14/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1413 - custom_cat: 0.9981 - loss: 0.7549 - val_accuracy: 0.1413 - val_custom_cat: 0.9944 - val_loss: 0.7595\n",
      "Epoch 15/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1405 - custom_cat: 0.9975 - loss: 0.7593 - val_accuracy: 0.1406 - val_custom_cat: 0.9959 - val_loss: 0.7569\n",
      "Epoch 16/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1402 - custom_cat: 0.9981 - loss: 0.7627 - val_accuracy: 0.1392 - val_custom_cat: 0.9941 - val_loss: 0.7630\n",
      "Epoch 17/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1406 - custom_cat: 0.9978 - loss: 0.7560 - val_accuracy: 0.1409 - val_custom_cat: 0.9957 - val_loss: 0.7576\n",
      "Epoch 18/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1411 - custom_cat: 0.9970 - loss: 0.7598 - val_accuracy: 0.1427 - val_custom_cat: 1.0005 - val_loss: 0.7830\n",
      "Epoch 19/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1421 - custom_cat: 0.9981 - loss: 0.7604 - val_accuracy: 0.1417 - val_custom_cat: 0.9993 - val_loss: 0.7696\n",
      "Epoch 20/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1416 - custom_cat: 0.9974 - loss: 0.7638 - val_accuracy: 0.1411 - val_custom_cat: 0.9981 - val_loss: 0.8199\n",
      "Epoch 21/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1417 - custom_cat: 0.9972 - loss: 0.7729 - val_accuracy: 0.1358 - val_custom_cat: 1.0047 - val_loss: 0.8948\n",
      "Epoch 22/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1432 - custom_cat: 0.9982 - loss: 0.7611 - val_accuracy: 0.1426 - val_custom_cat: 1.0027 - val_loss: 0.7968\n",
      "Epoch 23/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1434 - custom_cat: 0.9979 - loss: 0.7577 - val_accuracy: 0.1424 - val_custom_cat: 0.9971 - val_loss: 0.7620\n",
      "Epoch 24/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1432 - custom_cat: 0.9976 - loss: 0.7581 - val_accuracy: 0.1430 - val_custom_cat: 0.9956 - val_loss: 0.7590\n",
      "Epoch 25/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1434 - custom_cat: 0.9979 - loss: 0.7533 - val_accuracy: 0.1447 - val_custom_cat: 1.0007 - val_loss: 0.7870\n",
      "Epoch 26/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1437 - custom_cat: 0.9980 - loss: 0.7595 - val_accuracy: 0.1426 - val_custom_cat: 0.9947 - val_loss: 0.8239\n",
      "Epoch 27/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1430 - custom_cat: 0.9973 - loss: 0.7542 - val_accuracy: 0.1433 - val_custom_cat: 1.0004 - val_loss: 0.7714\n",
      "Epoch 28/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1432 - custom_cat: 0.9974 - loss: 0.7546 - val_accuracy: 0.1442 - val_custom_cat: 0.9986 - val_loss: 0.7544\n",
      "Epoch 29/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1434 - custom_cat: 0.9975 - loss: 0.7537 - val_accuracy: 0.1437 - val_custom_cat: 0.9951 - val_loss: 0.7576\n",
      "Epoch 30/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1432 - custom_cat: 0.9975 - loss: 0.7544 - val_accuracy: 0.1434 - val_custom_cat: 0.9962 - val_loss: 0.7558\n",
      "Epoch 31/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1430 - custom_cat: 0.9972 - loss: 0.7573 - val_accuracy: 0.1440 - val_custom_cat: 1.0042 - val_loss: 0.7873\n",
      "Epoch 32/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1431 - custom_cat: 0.9980 - loss: 0.7503 - val_accuracy: 0.1432 - val_custom_cat: 1.0003 - val_loss: 0.7630\n",
      "Epoch 33/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: 0.9976 - loss: 0.7582 - val_accuracy: 0.0854 - val_custom_cat: 1.0312 - val_loss: 1.2294\n",
      "Epoch 34/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1117 - custom_cat: 1.0957 - loss: 1.4861 - val_accuracy: 0.1192 - val_custom_cat: 0.9979 - val_loss: 0.9335\n",
      "Epoch 35/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1277 - custom_cat: 0.9972 - loss: 0.7611 - val_accuracy: 0.1362 - val_custom_cat: 0.9975 - val_loss: 0.8819\n",
      "Epoch 36/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1279 - custom_cat: 0.9979 - loss: 0.7521 - val_accuracy: 0.1325 - val_custom_cat: 0.9963 - val_loss: 0.8619\n",
      "Epoch 37/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1277 - custom_cat: 0.9980 - loss: 0.7602 - val_accuracy: 0.1372 - val_custom_cat: 0.9969 - val_loss: 0.8698\n",
      "Epoch 38/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1278 - custom_cat: 0.9973 - loss: 0.7580 - val_accuracy: 0.1382 - val_custom_cat: 0.9942 - val_loss: 0.8644\n",
      "Epoch 39/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1278 - custom_cat: 0.9975 - loss: 0.7575 - val_accuracy: 0.1377 - val_custom_cat: 0.9977 - val_loss: 0.8445\n",
      "Epoch 40/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1277 - custom_cat: 0.9974 - loss: 0.7578 - val_accuracy: 0.1375 - val_custom_cat: 0.9961 - val_loss: 0.8429\n",
      "Epoch 41/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1279 - custom_cat: 0.9975 - loss: 0.7559 - val_accuracy: 0.1375 - val_custom_cat: 0.9991 - val_loss: 0.8489\n",
      "Epoch 42/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1272 - custom_cat: 0.9974 - loss: 0.7552 - val_accuracy: 0.1342 - val_custom_cat: 1.0000 - val_loss: 0.8561\n",
      "Epoch 43/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1273 - custom_cat: 0.9980 - loss: 0.7581 - val_accuracy: 0.1258 - val_custom_cat: 0.9955 - val_loss: 0.8767\n",
      "Epoch 44/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1386 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1429 - custom_cat: nan - loss: nan - val_accuracy: 0.1429 - val_custom_cat: nan - val_loss: nan\n",
      "\u001b[1m1015/1015\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGdCAYAAADuR1K7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAf20lEQVR4nO3de3BU9f3/8deGkATFTcotayARbalEpNAGE8J0htbsGJSOpOKIGQSkGSkV0BpKAUUy2nbSilZQUMaZOgxVCoVaWpHi0GCVysoleOEWxnaUq5uAmA2iJDH5/P7wx9qVEMFvTpJ983zMnGE4+zm7n8+ZwD7ncHbxOeecAAAAjEjo6AkAAAC0JeIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAApiR29AQ6QnNzs44eParLLrtMPp+vo6cDAADOg3NOJ0+eVEZGhhISzn195qKMm6NHjyozM7OjpwEAAL6GQ4cOqV+/fud8/KKMm8suu0zS5yfH7/d38GwAAMD5qKurU2ZmZvR9/Fwuyrg5809Rfr+fuAEAIM581S0l3FAMAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADClXeJmyZIl6t+/v1JSUpSXl6dt27a1On716tUaOHCgUlJSNHjwYK1fv/6cY6dOnSqfz6eFCxe28awBAEA88jxuVq1apdLSUpWVlWnnzp0aMmSICgsLVVNT0+L4LVu2qLi4WCUlJXrzzTdVVFSkoqIi7d69+6yxf/3rX/XGG28oIyPD62UAAIA44Xnc/P73v9ddd92lyZMn65prrtHSpUt1ySWX6Nlnn21x/KJFizRq1CjNmjVL2dnZ+tWvfqXvfe97Wrx4ccy4I0eOaMaMGXr++efVtWtXr5cBAADihKdx09DQoMrKSgWDwS9eMCFBwWBQoVCoxWNCoVDMeEkqLCyMGd/c3KwJEyZo1qxZGjRo0FfOo76+XnV1dTEbAACwydO4OX78uJqampSenh6zPz09XeFwuMVjwuHwV47/3e9+p8TERN1zzz3nNY/y8nKlpqZGt8zMzAtcCQAAiBdx92mpyspKLVq0SMuWLZPP5zuvY+bOnatIJBLdDh065PEsAQBAR/E0bnr16qUuXbqouro6Zn91dbUCgUCLxwQCgVbHb968WTU1NcrKylJiYqISExN14MABzZw5U/3792/xOZOTk+X3+2M2AABgk6dxk5SUpJycHFVUVET3NTc3q6KiQvn5+S0ek5+fHzNekjZu3BgdP2HCBL3zzjt66623oltGRoZmzZqll19+2bvFAACAuJDo9QuUlpZq0qRJGjZsmHJzc7Vw4UKdOnVKkydPliRNnDhRffv2VXl5uSTp3nvv1ciRI/XYY49p9OjRWrlypXbs2KFnnnlGktSzZ0/17Nkz5jW6du2qQCCgq6++2uvlAACATs7zuBk3bpyOHTum+fPnKxwOa+jQodqwYUP0puGDBw8qIeGLC0gjRozQihUrNG/ePN1///0aMGCA1q5dq2uvvdbrqQIAAAN8zjnX0ZNob3V1dUpNTVUkEuH+GwAA4sT5vn/H3aelAAAAWkPcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwJR2iZslS5aof//+SklJUV5enrZt29bq+NWrV2vgwIFKSUnR4MGDtX79+uhjjY2Nmj17tgYPHqxLL71UGRkZmjhxoo4ePer1MgAAQBzwPG5WrVql0tJSlZWVaefOnRoyZIgKCwtVU1PT4vgtW7aouLhYJSUlevPNN1VUVKSioiLt3r1bkvTJJ59o586devDBB7Vz50698MIL2r9/v26++WavlwIAAOKAzznnvHyBvLw8XXfddVq8eLEkqbm5WZmZmZoxY4bmzJlz1vhx48bp1KlTWrduXXTf8OHDNXToUC1durTF19i+fbtyc3N14MABZWVlfeWc6urqlJqaqkgkIr/f/zVXBgAA2tP5vn97euWmoaFBlZWVCgaDX7xgQoKCwaBCoVCLx4RCoZjxklRYWHjO8ZIUiUTk8/mUlpbW4uP19fWqq6uL2QAAgE2exs3x48fV1NSk9PT0mP3p6ekKh8MtHhMOhy9o/OnTpzV79mwVFxefs+LKy8uVmpoa3TIzM7/GagAAQDyI609LNTY26rbbbpNzTk8//fQ5x82dO1eRSCS6HTp0qB1nCQAA2lOil0/eq1cvdenSRdXV1TH7q6urFQgEWjwmEAic1/gzYXPgwAFt2rSp1X97S05OVnJy8tdcBQAAiCeeXrlJSkpSTk6OKioqovuam5tVUVGh/Pz8Fo/Jz8+PGS9JGzdujBl/Jmzeffdd/fOf/1TPnj29WQAAAIg7nl65kaTS0lJNmjRJw4YNU25urhYuXKhTp05p8uTJkqSJEyeqb9++Ki8vlyTde++9GjlypB577DGNHj1aK1eu1I4dO/TMM89I+jxsbr31Vu3cuVPr1q1TU1NT9H6cHj16KCkpyeslAQCATszzuBk3bpyOHTum+fPnKxwOa+jQodqwYUP0puGDBw8qIeGLC0gjRozQihUrNG/ePN1///0aMGCA1q5dq2uvvVaSdOTIEf3973+XJA0dOjTmtV555RX94Ac/8HpJAACgE/P8e246I77nBgCA+NMpvucGAACgvRE3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMKVd4mbJkiXq37+/UlJSlJeXp23btrU6fvXq1Ro4cKBSUlI0ePBgrV+/PuZx55zmz5+vyy+/XN26dVMwGNS7777r5RIAAECc8DxuVq1apdLSUpWVlWnnzp0aMmSICgsLVVNT0+L4LVu2qLi4WCUlJXrzzTdVVFSkoqIi7d69OzrmkUce0RNPPKGlS5dq69atuvTSS1VYWKjTp097vRwAANDJ+ZxzzssXyMvL03XXXafFixdLkpqbm5WZmakZM2Zozpw5Z40fN26cTp06pXXr1kX3DR8+XEOHDtXSpUvlnFNGRoZmzpypX/ziF5KkSCSi9PR0LVu2TLfffvtXzqmurk6pqamKRCLy+/1ttFIAAOCl833/9vTKTUNDgyorKxUMBr94wYQEBYNBhUKhFo8JhUIx4yWpsLAwOv69995TOByOGZOamqq8vLxzPmd9fb3q6upiNgAAYJOncXP8+HE1NTUpPT09Zn96errC4XCLx4TD4VbHn/n1Qp6zvLxcqamp0S0zM/NrrQcAAHR+F8WnpebOnatIJBLdDh061NFTAgAAHvE0bnr16qUuXbqouro6Zn91dbUCgUCLxwQCgVbHn/n1Qp4zOTlZfr8/ZgMAADZ5GjdJSUnKyclRRUVFdF9zc7MqKiqUn5/f4jH5+fkx4yVp48aN0fFXXnmlAoFAzJi6ujpt3br1nM8JAAAuHolev0BpaakmTZqkYcOGKTc3VwsXLtSpU6c0efJkSdLEiRPVt29flZeXS5LuvfdejRw5Uo899phGjx6tlStXaseOHXrmmWckST6fTz//+c/161//WgMGDNCVV16pBx98UBkZGSoqKvJ6OQAAoJPzPG7GjRunY8eOaf78+QqHwxo6dKg2bNgQvSH44MGDSkj44gLSiBEjtGLFCs2bN0/333+/BgwYoLVr1+raa6+NjvnlL3+pU6dOacqUKaqtrdX3v/99bdiwQSkpKV4vBwAAdHKef89NZ8T33AAAEH86xffcAAAAtDfiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKZ4FjcnTpzQ+PHj5ff7lZaWppKSEn388cetHnP69GlNmzZNPXv2VPfu3TV27FhVV1dHH3/77bdVXFyszMxMdevWTdnZ2Vq0aJFXSwAAAHHIs7gZP3689uzZo40bN2rdunV67bXXNGXKlFaPue+++/Tiiy9q9erVevXVV3X06FHdcsst0ccrKyvVp08fPffcc9qzZ48eeOABzZ07V4sXL/ZqGQAAIM74nHOurZ903759uuaaa7R9+3YNGzZMkrRhwwbddNNNOnz4sDIyMs46JhKJqHfv3lqxYoVuvfVWSVJVVZWys7MVCoU0fPjwFl9r2rRp2rdvnzZt2nTe86urq1NqaqoikYj8fv/XWCEAAGhv5/v+7cmVm1AopLS0tGjYSFIwGFRCQoK2bt3a4jGVlZVqbGxUMBiM7hs4cKCysrIUCoXO+VqRSEQ9evRou8kDAIC4lujFk4bDYfXp0yf2hRIT1aNHD4XD4XMek5SUpLS0tJj96enp5zxmy5YtWrVqlV566aVW51NfX6/6+vro7+vq6s5jFQAAIB5d0JWbOXPmyOfztbpVVVV5NdcYu3fv1pgxY1RWVqYbbrih1bHl5eVKTU2NbpmZme0yRwAA0P4u6MrNzJkzdeedd7Y65qqrrlIgEFBNTU3M/s8++0wnTpxQIBBo8bhAIKCGhgbV1tbGXL2prq4+65i9e/eqoKBAU6ZM0bx5875y3nPnzlVpaWn093V1dQQOAABGXVDc9O7dW7179/7Kcfn5+aqtrVVlZaVycnIkSZs2bVJzc7Py8vJaPCYnJ0ddu3ZVRUWFxo4dK0nav3+/Dh48qPz8/Oi4PXv26Prrr9ekSZP0m9/85rzmnZycrOTk5PMaCwAA4psnn5aSpBtvvFHV1dVaunSpGhsbNXnyZA0bNkwrVqyQJB05ckQFBQVavny5cnNzJUk/+9nPtH79ei1btkx+v18zZsyQ9Pm9NdLn/xR1/fXXq7CwUAsWLIi+VpcuXc4rus7g01IAAMSf833/9uSGYkl6/vnnNX36dBUUFCghIUFjx47VE088EX28sbFR+/fv1yeffBLd9/jjj0fH1tfXq7CwUE899VT08TVr1ujYsWN67rnn9Nxzz0X3X3HFFXr//fe9WgoAAIgjnl256cy4cgMAQPzp0O+5AQAA6CjEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCmexc2JEyc0fvx4+f1+paWlqaSkRB9//HGrx5w+fVrTpk1Tz5491b17d40dO1bV1dUtjv3www/Vr18/+Xw+1dbWerACAAAQjzyLm/Hjx2vPnj3auHGj1q1bp9dee01Tpkxp9Zj77rtPL774olavXq1XX31VR48e1S233NLi2JKSEn3nO9/xYuoAACCO+Zxzrq2fdN++fbrmmmu0fft2DRs2TJK0YcMG3XTTTTp8+LAyMjLOOiYSiah3795asWKFbr31VklSVVWVsrOzFQqFNHz48OjYp59+WqtWrdL8+fNVUFCgjz76SGlpaec9v7q6OqWmpioSicjv9//fFgsAANrF+b5/e3LlJhQKKS0tLRo2khQMBpWQkKCtW7e2eExlZaUaGxsVDAaj+wYOHKisrCyFQqHovr179+rhhx/W8uXLlZBwftOvr69XXV1dzAYAAGzyJG7C4bD69OkTsy8xMVE9evRQOBw+5zFJSUlnXYFJT0+PHlNfX6/i4mItWLBAWVlZ5z2f8vJypaamRrfMzMwLWxAAAIgbFxQ3c+bMkc/na3Wrqqryaq6aO3eusrOzdccdd1zwcZFIJLodOnTIoxkCAICOlnghg2fOnKk777yz1TFXXXWVAoGAampqYvZ/9tlnOnHihAKBQIvHBQIBNTQ0qLa2NubqTXV1dfSYTZs2adeuXVqzZo0k6cztQr169dIDDzyghx56qMXnTk5OVnJy8vksEQAAxLkLipvevXurd+/eXzkuPz9ftbW1qqysVE5OjqTPw6S5uVl5eXktHpOTk6OuXbuqoqJCY8eOlSTt379fBw8eVH5+viTpL3/5iz799NPoMdu3b9dPfvITbd68Wd/85jcvZCkAAMCoC4qb85Wdna1Ro0bprrvu0tKlS9XY2Kjp06fr9ttvj35S6siRIyooKNDy5cuVm5ur1NRUlZSUqLS0VD169JDf79eMGTOUn58f/aTUlwPm+PHj0de7kE9LAQAAuzyJG0l6/vnnNX36dBUUFCghIUFjx47VE088EX28sbFR+/fv1yeffBLd9/jjj0fH1tfXq7CwUE899ZRXUwQAAAZ58j03nR3fcwMAQPzp0O+5AQAA6CjEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMCWxoyfQEZxzkqS6uroOngkAADhfZ963z7yPn8tFGTcnT56UJGVmZnbwTAAAwIU6efKkUlNTz/m4z31V/hjU3Nyso0eP6rLLLpPP5+vo6XS4uro6ZWZm6tChQ/L7/R09HbM4z+2D89w+OM/tg/McyzmnkydPKiMjQwkJ576z5qK8cpOQkKB+/fp19DQ6Hb/fzx+edsB5bh+c5/bBeW4fnOcvtHbF5gxuKAYAAKYQNwAAwBTiBkpOTlZZWZmSk5M7eiqmcZ7bB+e5fXCe2wfn+eu5KG8oBgAAdnHlBgAAmELcAAAAU4gbAABgCnEDAABMIW4uAidOnND48ePl9/uVlpamkpISffzxx60ec/r0aU2bNk09e/ZU9+7dNXbsWFVXV7c49sMPP1S/fv3k8/lUW1vrwQrigxfn+e2331ZxcbEyMzPVrVs3ZWdna9GiRV4vpdNZsmSJ+vfvr5SUFOXl5Wnbtm2tjl+9erUGDhyolJQUDR48WOvXr4953Dmn+fPn6/LLL1e3bt0UDAb17rvvermEuNCW57mxsVGzZ8/W4MGDdemllyojI0MTJ07U0aNHvV5Gp9fWP8//a+rUqfL5fFq4cGEbzzrOOJg3atQoN2TIEPfGG2+4zZs3u29961uuuLi41WOmTp3qMjMzXUVFhduxY4cbPny4GzFiRItjx4wZ42688UYnyX300UcerCA+eHGe//CHP7h77rnH/etf/3L//e9/3R//+EfXrVs39+STT3q9nE5j5cqVLikpyT377LNuz5497q677nJpaWmuurq6xfGvv/6669Kli3vkkUfc3r173bx581zXrl3drl27omN++9vfutTUVLd27Vr39ttvu5tvvtldeeWV7tNPP22vZXU6bX2ea2trXTAYdKtWrXJVVVUuFAq53Nxcl5OT057L6nS8+Hk+44UXXnBDhgxxGRkZ7vHHH/d4JZ0bcWPc3r17nSS3ffv26L5//OMfzufzuSNHjrR4TG1trevatatbvXp1dN++ffucJBcKhWLGPvXUU27kyJGuoqLioo4br8/z/7r77rvdD3/4w7abfCeXm5vrpk2bFv19U1OTy8jIcOXl5S2Ov+2229zo0aNj9uXl5bmf/vSnzjnnmpubXSAQcAsWLIg+Xltb65KTk92f/vQnD1YQH9r6PLdk27ZtTpI7cOBA20w6Dnl1ng8fPuz69u3rdu/e7a644oqLPm74ZynjQqGQ0tLSNGzYsOi+YDCohIQEbd26tcVjKisr1djYqGAwGN03cOBAZWVlKRQKRfft3btXDz/8sJYvX97qf2B2MfDyPH9ZJBJRjx492m7ynVhDQ4MqKytjzlFCQoKCweA5z1EoFIoZL0mFhYXR8e+9957C4XDMmNTUVOXl5bV63i3z4jy3JBKJyOfzKS0trU3mHW+8Os/Nzc2aMGGCZs2apUGDBnkz+Thzcb8jXQTC4bD69OkTsy8xMVE9evRQOBw+5zFJSUln/QWUnp4ePaa+vl7FxcVasGCBsrKyPJl7PPHqPH/Zli1btGrVKk2ZMqVN5t3ZHT9+XE1NTUpPT4/Z39o5CofDrY4/8+uFPKd1XpznLzt9+rRmz56t4uLii/Y/gPTqPP/ud79TYmKi7rnnnrafdJwibuLUnDlz5PP5Wt2qqqo8e/25c+cqOztbd9xxh2ev0Rl09Hn+X7t379aYMWNUVlamG264oV1eE2gLjY2Nuu222+Sc09NPP93R0zGlsrJSixYt0rJly+Tz+Tp6Op1GYkdPAF/PzJkzdeedd7Y65qqrrlIgEFBNTU3M/s8++0wnTpxQIBBo8bhAIKCGhgbV1tbGXFWorq6OHrNp0ybt2rVLa9askfT5p08kqVevXnrggQf00EMPfc2VdS4dfZ7P2Lt3rwoKCjRlyhTNmzfva60lHvXq1UtdunQ565N6LZ2jMwKBQKvjz/xaXV2tyy+/PGbM0KFD23D28cOL83zGmbA5cOCANm3adNFetZG8Oc+bN29WTU1NzBX0pqYmzZw5UwsXLtT777/ftouIFx190w+8deZG1x07dkT3vfzyy+d1o+uaNWui+6qqqmJudP3Pf/7jdu3aFd2effZZJ8lt2bLlnHf9W+bVeXbOud27d7s+ffq4WbNmebeATiw3N9dNnz49+vumpibXt2/fVm/A/NGPfhSzLz8//6wbih999NHo45FIhBuK2/g8O+dcQ0ODKyoqcoMGDXI1NTXeTDzOtPV5Pn78eMzfxbt27XIZGRlu9uzZrqqqyruFdHLEzUVg1KhR7rvf/a7bunWr+/e//+0GDBgQ8xHlw4cPu6uvvtpt3bo1um/q1KkuKyvLbdq0ye3YscPl5+e7/Pz8c77GK6+8clF/Wso5b87zrl27XO/evd0dd9zhPvjgg+h2Mb1RrFy50iUnJ7tly5a5vXv3uilTpri0tDQXDoedc85NmDDBzZkzJzr+9ddfd4mJie7RRx91+/btc2VlZS1+FDwtLc397W9/c++8844bM2YMHwVv4/Pc0NDgbr75ZtevXz/31ltvxfz81tfXd8gaOwMvfp6/jE9LETcXhQ8//NAVFxe77t27O7/f7yZPnuxOnjwZffy9995zktwrr7wS3ffpp5+6u+++233jG99wl1xyifvxj3/sPvjgg3O+BnHjzXkuKytzks7arrjiinZcWcd78sknXVZWlktKSnK5ubnujTfeiD42cuRIN2nSpJjxf/7zn923v/1tl5SU5AYNGuReeumlmMebm5vdgw8+6NLT011ycrIrKChw+/fvb4+ldGpteZ7P/Ly3tP3vn4GLUVv/PH8ZceOcz7n/f7MEAACAAXxaCgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABM+X9JnGEujayxKgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.model_selection as sk\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Input\n",
    "import tensorflow.keras.backend as kb\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import random\n",
    "\n",
    "################################################GONNA SWITCH FROM -1,0,1 to 0,1,2\n",
    "#gonna work in radians\n",
    "\n",
    "################### GLOBAL VARIABLES\n",
    "\n",
    "NUMANGLES = 400 #how many orientations each side can take\n",
    "\n",
    "MAXPROB = .5 #Max probability the mouse is correct\n",
    "\n",
    "\n",
    "ANGLEMAX = np.pi/2 #maximum bar orientation angle\n",
    "ANGLEMIN = -np.pi/2 #minimum bar orientation angle\n",
    "\n",
    "LEFTCHOICEVAL = -1  #Value output when choosing left bar\n",
    "RIGHTCHOICEVAL = 1 #Value output when choosing right bar\n",
    "\n",
    "UNITS = 256 # Number of neurons in the dense layer\n",
    "OUTPUT_SIZE = 1 # Number of output states\n",
    "\n",
    "STIMULUSDURATION = 6 #length of the stimulus (seconds)\n",
    "PRESTIMULUSDURATION = 1 #length of the pre stimulus (seconds)\n",
    "\n",
    "FRAMERATE = 22 #(hz)\n",
    "\n",
    "TOTALFRAMES = int(FRAMERATE*(STIMULUSDURATION + PRESTIMULUSDURATION)) #total number of frames\n",
    "\n",
    "LASTFRAME = TOTALFRAMES - 1 #index of the last frame\n",
    "\n",
    "PRESTIMULUSFRAME = int(PRESTIMULUSDURATION * FRAMERATE - 1) #index of the frame immediately before stimulus\n",
    "\n",
    "################################################################################################################################## END GLOBAL VARIABLES\n",
    "\n",
    "\n",
    "angleList = np.linspace(ANGLEMAX, ANGLEMIN, NUMANGLES) #list of all angles to be trained on\n",
    "\n",
    "def difficulty(angle1, angle2):\n",
    "    '''Uses fancy but probably unecessarily complicated math to assign a difficulty to two input angles\n",
    "       Difficulty ranges from 0 to 1'''\n",
    "    sameSign = True\n",
    "    difference = abs( abs(angle1) - abs(angle2) )\n",
    "\n",
    "    if abs(angle1 + angle2) < abs(angle1)+abs(angle2): #if they are opposite sign\n",
    "        sameSign = False\n",
    "        \n",
    "    beta = 0.06 #slope parameter for steepness of difficulty curve (a function of angle separation)\n",
    "    alpha = .1 #Value of difficulty at angle difference of max\n",
    "\n",
    "    offset = np.arctanh( 2*alpha - 1 )/beta #shift the graph so at x = 0 f(x) is alpha\n",
    "\n",
    "    f = .4 #Parameter for the slope of the mapping of difference to input to the difficulty function\n",
    "    \n",
    "    if not sameSign: #the angles are not the same side so add a bias to the difficulty\n",
    "        y = 0.6  #parameter affecting how much f is changed when the angles are on same side or not\n",
    "        f = f - y*f\n",
    "\n",
    "    x = 1/(f*difference) #scale it so small differences are large value and big differences are small\n",
    "    dif = 1/2 * ( np.tanh( beta * (x + offset) ) + 1 )\n",
    "    return dif\n",
    "\n",
    "\n",
    "#Generate training data\n",
    "\n",
    "#list that holds the pairs [left angle, right angle]\n",
    "anglePairs = []\n",
    "\n",
    "#generate all pairs of angles\n",
    "for i in angleList:\n",
    "    for j in angleList:      #round to deal with floating point error\n",
    "        decimals = 1\n",
    "        if (round(i,decimals) != round(j,decimals)) & (-round(i,decimals) != round(j,decimals)): #we dont want any pairs that have equal verticallity (same abs(angle))\n",
    "            #add noise to the angles\n",
    "            noiseScale = 10 #scales how noise the angles are\n",
    "            i += np.random.randn()/noiseScale\n",
    "            j += np.random.randn()/noiseScale\n",
    "            anglePairs.append([i,j])\n",
    "\n",
    "\n",
    "#make the list a np array \n",
    "angPair = np.zeros((len(anglePairs), 2))\n",
    "counter = 0\n",
    "for i in anglePairs:\n",
    "    angPair[counter][0] = i[0]\n",
    "    angPair[counter][1] = i[1]\n",
    "    counter +=1\n",
    "anglePairs = angPair\n",
    "\n",
    "np.random.shuffle(anglePairs) #randomly organize list for training\n",
    "\n",
    "\n",
    "def correctChoice(angle1, angle2):\n",
    "    '''input 2 angles return the smaller angle corresponding to more vertical orientation\n",
    "       Angle 1 is left angle 2 is right. Returns -1 for Left 1 for right\n",
    "       if they are equal error is thrown because currently only training on non equal angles\n",
    "    '''\n",
    "    global LEFTCHOICEVAL, RIGHTCHOICEVAL\n",
    "    if angle1 < angle2:\n",
    "        return LEFTCHOICEVAL        #The left bar is oriented more vertically\n",
    "    elif angle2 < angle1:\n",
    "        return RIGHTCHOICEVAL        #The right bar is oriented more vertically\n",
    "    else:\n",
    "        return \"Error. Not expecting equal angles\" #throw error if angles are equal\n",
    "\n",
    "\n",
    "def trainedChoice(angle1, angle2):\n",
    "    '''Input two angles returns the choice the mouse makes'''\n",
    "    global LEFTCHOICEVAL, RIGHTCHOICEVAL\n",
    "\n",
    "    cor = correctChoice(angle1,angle2)\n",
    "\n",
    "    n = np.random.random()\n",
    "\n",
    "    if n <= probablilityCorrect(difficulty(angle1, angle2)): #they are certain\n",
    "        return cor\n",
    "    else:#not certain so take a guess\n",
    "        g = np.random.rand()\n",
    "        if g < .5:\n",
    "            return cor\n",
    "        else:\n",
    "            if cor == RIGHTCHOICEVAL:\n",
    "                return LEFTCHOICEVAL\n",
    "            else:\n",
    "                return RIGHTCHOICEVAL\n",
    "            \n",
    "def probablilityCorrect(difficulty):\n",
    "    '''takes an input difficulty ranging from 0 to 1 and outputs a probability from .5 to 1 corresponding to the prob the mouse is correct'''\n",
    "    global MAXPROB\n",
    "    p = -0.5*difficulty + 1\n",
    "    if p > MAXPROB:\n",
    "        p = MAXPROB\n",
    "    return p\n",
    "\n",
    "\n",
    "    \n",
    "numberTrials = len(anglePairs)\n",
    "\n",
    "#create the lists of trained and correct choices\n",
    "corCh = np.zeros(numberTrials) #List of correct choices\n",
    "trainedCh = np.zeros(numberTrials) #List of trained choices\n",
    "\n",
    "counter = 0\n",
    "for i in anglePairs:\n",
    "    angle1 = i[0]\n",
    "    angle2 = i[1]\n",
    "    corCh[counter] = correctChoice(angle1, angle2)\n",
    "    trainedCh[counter] = trainedChoice(angle1, angle2)\n",
    "    counter += 1\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trialsData = np.zeros((numberTrials, TOTALFRAMES, 2)).astype(np.float32) #stores the trials time series'. This is the input time series\n",
    "\n",
    "responseData = np.full((numberTrials, TOTALFRAMES), np.nan) #stores the response time series. This is the output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for iteration in range(numberTrials): #for each experiment create a time series\n",
    "    for frame in range(TOTALFRAMES): \n",
    "        if frame <= PRESTIMULUSFRAME: #startwith [0,0] when no stimulus present\n",
    "            g = np.random.randint(0,3)\n",
    "            if g ==0:\n",
    "                trialsData[iteration][frame][0] = np.pi\n",
    "                trialsData[iteration][frame][1] = np.pi\n",
    "            elif g ==1:\n",
    "                trialsData[iteration][frame][0] = -np.pi\n",
    "                trialsData[iteration][frame][1] = -np.pi\n",
    "            elif g ==2:\n",
    "                trialsData[iteration][frame][0] = np.pi\n",
    "                trialsData[iteration][frame][1] = -np.pi   \n",
    "            elif g ==3:\n",
    "                trialsData[iteration][frame][0] = -np.pi\n",
    "                trialsData[iteration][frame][1] = np.pi\n",
    "                \n",
    "            \n",
    "            responseData[iteration][frame] = 0\n",
    "            #if frame == PRESTIMULUSFRAME: #frame before stimulus\n",
    "            #    responseData[iteration][frame] = 0\n",
    "        else:\n",
    "            #use the angles corresponding to stimulus\n",
    "            trialsData[iteration][frame][0] = anglePairs[iteration][0]\n",
    "            trialsData[iteration][frame][1] = anglePairs[iteration][1]\n",
    "            if frame == LASTFRAME   :#last frame\n",
    "                responseData[iteration][frame] = trainedCh[iteration]\n",
    "                \n",
    "            \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = sk.train_test_split(trialsData, \n",
    "                                        responseData, \n",
    "                                        test_size=0.25, \n",
    "                                        random_state=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def custom_loss(y_actual,y_pred): \n",
    "    '''calculates the loss using the frame immediately before stimulus and last frame of time series\n",
    "       The frame before stim is to set p left and p right = 0'''\n",
    "    #l1 = kb.sparse_categorical_crossentropy(y_actual[:, PRESTIMULUSFRAME], y_pred[:, PRESTIMULUSFRAME])\n",
    "    #l2 = kb.sparse_categorical_crossentropy(y_actual[:, LASTFRAME][0], y_pred[:, LASTFRAME])\n",
    "    l1 = kb.mean(kb.square(y_actual[:,PRESTIMULUSFRAME] - y_pred[:,PRESTIMULUSFRAME]))\n",
    "    l2 = kb.mean(kb.square(y_actual[:,LASTFRAME] - y_pred[:,LASTFRAME]))\n",
    "    custom_loss = l1 + l2\n",
    "    #custom_loss = l2\n",
    "    return custom_loss\n",
    "\n",
    "\n",
    "def custom_cat(y_actual,y_pred):\n",
    "    '''Checks the accuracy of the final predicted output and compares it to the desired output'''\n",
    "    #l2 = tf.keras.metrics.sparse_categorical_accuracy(y_actual[:, LASTFRAME], y_pred[:, LASTFRAME])\n",
    "    l2 = kb.mean(kb.abs(y_actual[:, LASTFRAME] - y_pred[:, LASTFRAME]))\n",
    "    custom_cat = l2\n",
    "    return custom_cat\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Input(shape = (xTrain.shape[1], xTrain.shape[2])))\n",
    "model.add(layers.SimpleRNN(UNITS, activation = 'relu', return_sequences = True, name = 'rnn'))\n",
    "model.add(layers.BatchNormalization(name = 'batch_norm'))\n",
    "model.add(layers.Dense(OUTPUT_SIZE, activation = 'linear', name = 'outputprobs'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "batch_size = 660 # Trials per batch\n",
    "MAX_EPOCHS = 100 # Total epochs\n",
    "\n",
    "metrr = ['accuracy', custom_cat]\n",
    "\n",
    "model.compile(\n",
    "    loss=custom_loss,\n",
    "    #loss = \"mean_squared_error\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=metrr,\n",
    ")\n",
    "\n",
    "\n",
    "#print(xTrain.shape)\n",
    "history = model.fit(xTrain, yTrain, epochs = MAX_EPOCHS, batch_size = batch_size, verbose = True,\n",
    "   validation_data = (xTest, yTest))\n",
    "yTestPredict = model.predict(xTest)\n",
    "#print(yTestPredict.shape, \"shapers\")\n",
    "\n",
    "\n",
    "one = []\n",
    "two = []\n",
    "three = []\n",
    "\n",
    "i = np.random.randint(0,numberTrials*.25)\n",
    "for a in yTestPredict[i]:\n",
    "    one.append(a[0])\n",
    "    #two.append(a[1])\n",
    "    #three.append(a[2])\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(one, c='r')\n",
    "#plt.plot(two, c='g')\n",
    "#plt.plot(three,c='b')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
