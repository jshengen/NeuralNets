{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_50\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_50\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ outputprobs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m66,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm (\u001b[38;5;33mBatchNormalization\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ outputprobs (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,585</span> (264.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,585\u001b[0m (264.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,073</span> (262.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,073\u001b[0m (262.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step - accuracy: 0.0082 - custom_cat: 1.0379 - loss: 1.7809 - val_accuracy: 0.0000e+00 - val_custom_cat: 1.0511 - val_loss: 1.1167\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0071 - custom_cat: 0.9790 - loss: 1.5227 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8823 - val_loss: 0.7894\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0184 - custom_cat: 0.7900 - loss: 0.9580 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7816 - val_loss: 0.6194\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0170 - custom_cat: 1.3584 - loss: 2.2233 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8462 - val_loss: 0.7285\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0080 - custom_cat: 0.9006 - loss: 1.3087 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7878 - val_loss: 0.6312\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0075 - custom_cat: 0.5552 - loss: 0.5033 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6772 - val_loss: 0.4810\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0165 - custom_cat: 0.3662 - loss: 0.2843 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.5546 - val_loss: 0.3335\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0170 - custom_cat: 0.6853 - loss: 1.1276 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.4847 - val_loss: 0.2608\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0172 - custom_cat: 1.5229 - loss: 2.8490 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.5403 - val_loss: 0.3155\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0173 - custom_cat: 0.7574 - loss: 1.1410 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.5869 - val_loss: 0.3681\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0145 - custom_cat: 0.3758 - loss: 0.2647 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.5982 - val_loss: 0.3825\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.4590 - loss: 2.5061 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6687 - val_loss: 0.4770\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.7335 - loss: 0.7643 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6805 - val_loss: 0.4863\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.3153e-04 - custom_cat: 1.3641 - loss: 2.0698 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8076 - val_loss: 0.6702\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 9.3165e-04 - custom_cat: 0.9600 - loss: 1.0876 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8151 - val_loss: 0.6782\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 9.5069e-04 - custom_cat: 1.0672 - loss: 1.2368 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8464 - val_loss: 0.7253\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0025 - custom_cat: 1.0907 - loss: 1.3237 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9011 - val_loss: 0.8166\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0042 - custom_cat: 0.9576 - loss: 1.0577 - val_accuracy: 0.0000e+00 - val_custom_cat: 1.0099 - val_loss: 1.0258\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0063 - custom_cat: 1.1482 - loss: 1.5126 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9995 - val_loss: 1.0067\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0047 - custom_cat: 0.8936 - loss: 1.0029 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9740 - val_loss: 0.9567\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0047 - custom_cat: 0.9766 - loss: 1.0937 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9422 - val_loss: 0.8960\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 8.5003e-04 - custom_cat: 1.0497 - loss: 1.1638 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8544 - val_loss: 0.7389\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9950 - loss: 1.0808 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8059 - val_loss: 0.6593\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.8617 - loss: 0.9519 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7603 - val_loss: 0.5888\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.0354 - loss: 1.3746 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7524 - val_loss: 0.5769\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9682 - loss: 1.1829 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7619 - val_loss: 0.5906\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.8240 - loss: 0.8929 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8027 - val_loss: 0.6536\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.7970 - loss: 0.6657 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8138 - val_loss: 0.6721\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - custom_cat: 0.7407 - loss: 0.5631 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7957 - val_loss: 0.6434\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.6645 - loss: 0.4614 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7281 - val_loss: 0.5420\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.5001 - loss: 0.2889 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6494 - val_loss: 0.4372\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9695 - loss: 1.3310 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6082 - val_loss: 0.3873\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.3472 - loss: 0.1854 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.5936 - val_loss: 0.3701\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.5552 - loss: 0.5131 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.5825 - val_loss: 0.3575\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.6667 - loss: 2.8384 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6345 - val_loss: 0.4193\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.5076 - loss: 2.3712 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7591 - val_loss: 0.5985\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0044 - custom_cat: 1.0813 - loss: 1.5244 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8735 - val_loss: 0.7983\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0065 - custom_cat: 1.0232 - loss: 1.4548 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9219 - val_loss: 0.8787\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0060 - custom_cat: 1.0367 - loss: 1.3636 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9095 - val_loss: 0.8386\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0023 - custom_cat: 0.9182 - loss: 0.9841 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8534 - val_loss: 0.7330\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.0334 - loss: 1.1664 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8056 - val_loss: 0.6571\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 9.3950e-06 - custom_cat: 1.1364 - loss: 1.4379 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8415 - val_loss: 0.7177\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9159 - loss: 0.9878 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8720 - val_loss: 0.7704\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - custom_cat: 0.8911 - loss: 0.8271 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8506 - val_loss: 0.7351\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.7547 - loss: 0.6155 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8029 - val_loss: 0.6535\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.7797 - loss: 0.6709 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7383 - val_loss: 0.5539\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.1815 - loss: 1.5763 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7413 - val_loss: 0.5590\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.1698 - loss: 1.5349 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7868 - val_loss: 0.6288\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0334e-04 - custom_cat: 1.2205 - loss: 1.6374 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8799 - val_loss: 0.7881\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0020 - custom_cat: 1.0434 - loss: 1.3339 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9597 - val_loss: 0.9373\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0030 - custom_cat: 0.8742 - loss: 1.0116 - val_accuracy: 0.0000e+00 - val_custom_cat: 1.0318 - val_loss: 1.0788\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0044 - custom_cat: 1.0981 - loss: 1.3972 - val_accuracy: 0.0000e+00 - val_custom_cat: 1.0715 - val_loss: 1.1659\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0056 - custom_cat: 0.9672 - loss: 1.1007 - val_accuracy: 0.0000e+00 - val_custom_cat: 1.0583 - val_loss: 1.1485\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0063 - custom_cat: 1.1201 - loss: 1.4307 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9784 - val_loss: 0.9972\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0057 - custom_cat: 1.0108 - loss: 1.2451 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9252 - val_loss: 0.8824\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0024 - custom_cat: 0.8668 - loss: 0.8859 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8153 - val_loss: 0.6756\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.6733 - loss: 0.5184 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6885 - val_loss: 0.4891\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9897 - loss: 1.2608 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6182 - val_loss: 0.4055\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9519 - loss: 1.2220 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6204 - val_loss: 0.4179\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.7241 - loss: 0.6750 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6451 - val_loss: 0.4570\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.0737 - loss: 1.3965 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6889 - val_loss: 0.5228\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.7613 - loss: 0.7281 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6571 - val_loss: 0.4627\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.0027 - loss: 1.2209 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6433 - val_loss: 0.4345\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.8067 - loss: 0.9285 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6737 - val_loss: 0.4702\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 6.5765e-05 - custom_cat: 1.3767 - loss: 2.0107 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7844 - val_loss: 0.6277\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0031 - custom_cat: 1.1715 - loss: 1.6143 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9844 - val_loss: 0.9835\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0070 - custom_cat: 1.0290 - loss: 1.3305 - val_accuracy: 0.0000e+00 - val_custom_cat: 1.0592 - val_loss: 1.1354\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0039 - custom_cat: 0.9608 - loss: 1.1051 - val_accuracy: 5.6306e-05 - val_custom_cat: 1.1281 - val_loss: 1.2884\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0028 - custom_cat: 1.0204 - loss: 1.1991 - val_accuracy: 5.6306e-05 - val_custom_cat: 1.1656 - val_loss: 1.3740\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0026 - custom_cat: 1.2151 - loss: 1.5751 - val_accuracy: 0.0000e+00 - val_custom_cat: 1.0816 - val_loss: 1.1813\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.4167e-04 - custom_cat: 0.9862 - loss: 1.0039 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9992 - val_loss: 1.0095\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.8536 - loss: 0.7596 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8809 - val_loss: 0.7883\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.6446 - loss: 0.4781 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7210 - val_loss: 0.5387\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 1.2069 - loss: 1.7234 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6520 - val_loss: 0.4496\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.4475 - loss: 0.2978 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6126 - val_loss: 0.4033\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.5656 - loss: 2.5526 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.6575 - val_loss: 0.4642\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - custom_cat: 0.6575 - loss: 0.5808 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7140 - val_loss: 0.5429\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - custom_cat: 0.5786 - loss: 0.4114 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7386 - val_loss: 0.5722\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.1638 - loss: 1.4972 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.7895 - val_loss: 0.6417\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.2645 - loss: 1.6530 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9546 - val_loss: 0.9222\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 6.3479e-04 - custom_cat: 0.9898 - loss: 1.0389 - val_accuracy: 0.0000e+00 - val_custom_cat: 1.0046 - val_loss: 1.0248\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.4475e-04 - custom_cat: 1.0002 - loss: 1.0382 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9704 - val_loss: 0.9659\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9934 - loss: 1.0126 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8530 - val_loss: 0.7590\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - custom_cat: 1.1892 - loss: 1.4482 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8864 - val_loss: 0.8075\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9128 - loss: 0.8301 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9090 - val_loss: 0.8406\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9895 - loss: 0.9928 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9450 - val_loss: 0.9045\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.5708e-05 - custom_cat: 1.0246 - loss: 1.0748 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9936 - val_loss: 1.0007\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 8.5003e-05 - custom_cat: 1.0162 - loss: 1.0546 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9550 - val_loss: 0.9309\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.0147 - loss: 1.0378 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9364 - val_loss: 0.8996\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9857 - loss: 0.9893 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9173 - val_loss: 0.8643\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 1.0316 - loss: 1.0688 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9241 - val_loss: 0.8730\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.0176 - loss: 1.0450 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9414 - val_loss: 0.9029\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9746 - loss: 0.9437 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8753 - val_loss: 0.7879\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.0565 - loss: 1.1255 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8767 - val_loss: 0.7900\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 1.0895 - loss: 1.2091 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9495 - val_loss: 0.9187\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9632 - loss: 0.9342 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.9193 - val_loss: 0.8634\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9564 - loss: 0.9056 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8288 - val_loss: 0.7114\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - custom_cat: 1.1325 - loss: 1.3443 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8362 - val_loss: 0.7228\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.8799 - loss: 0.7763 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8122 - val_loss: 0.6848\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - custom_cat: 0.9160 - loss: 0.9070 - val_accuracy: 0.0000e+00 - val_custom_cat: 0.8077 - val_loss: 0.6786\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyjElEQVR4nO3df3RU9Z3/8dckIRNCSAIGEgKRn65IEYKhpLFVsUSDulatuydaT8GUxuMPztpGPZr+AH+cnrBqKa1lZdWyntYfsO5KbaviahC62CgSSPEnK36x/JwEVJKQQBIy9/vH7SQzMEnmx71zZ5Ln45x75s6dO/e+GefAy/f93M+4DMMwBAAAkGCSnC4AAAAgEoQYAACQkAgxAAAgIRFiAABAQiLEAACAhESIAQAACYkQAwAAEhIhBgAAJKQUpwuwmtfr1aFDhzRy5Ei5XC6nywEAACEwDEOtra3Kz89XUlJoPZZBF2IOHTqkgoICp8sAAAAR2L9/vyZMmBDSvjEJMatXr9Yjjzwij8ej2bNn67HHHtO8efOC7vv000+roqIiYJvb7dbJkydDOtfIkSMlmR9CZmZmdIUDAICYaGlpUUFBQc+/46GwPcSsX79eVVVVWrNmjYqLi7Vq1SqVlZVp9+7dGjt2bND3ZGZmavfu3T3Pw7ks5Ns3MzOTEAMAQIIJ59982wf2rly5UpWVlaqoqNCMGTO0Zs0apaena+3atX2+x+VyKS8vr2fJzc21u0wAAJBgbA0xnZ2dqq+vV2lpae8Jk5JUWlqqurq6Pt93/PhxTZw4UQUFBbrmmmv0wQcf9LlvR0eHWlpaAhYAADD42Rpijh49qu7u7jM6Kbm5ufJ4PEHfc+6552rt2rV66aWX9Mwzz8jr9erCCy/UgQMHgu5fU1OjrKysnoVBvQAADA1xN09MSUmJFi1apMLCQl1yySV68cUXNWbMGP37v/970P2rq6vV3Nzcs+zfvz/GFQMAACfYOrA3JydHycnJamxsDNje2NiovLy8kI4xbNgwzZkzR3v27An6utvtltvtjrpWAACQWGztxKSmpqqoqEi1tbU927xer2pra1VSUhLSMbq7u/Xee+9p3LhxdpUJAAASkO23WFdVVWnx4sWaO3eu5s2bp1WrVqmtra1nLphFixZp/PjxqqmpkSQ9+OCD+trXvqZp06bp2LFjeuSRR/S3v/1N3//+9+0uFQAAJBDbQ0x5ebmOHDmiZcuWyePxqLCwUBs3buwZ7Ltv376A6YW//PJLVVZWyuPxaNSoUSoqKtJf/vIXzZgxw+5SAQBAAnEZhmE4XYSVWlpalJWVpebmZia7AwAgQUTy73fc3Z0EAAAQCkIMAABISIQYAACQkAgxAKz10kvSCy84XQWAIcD2u5MADCFdXVJ5udTdLS1cKI0c6XRFAAYxOjEArNPSInV0SKdOSV984XQ1AAY5QgwA6/j/ijy/KA/AZoQYANZpbe1dJ8QAsBkhBoB16MQAiCFCDADrEGIAxBAhBoB1uJwEIIYIMQCsQycGQAwRYgBYx78T09zsXB0AhgRCDADr0IkBEEOEGADWYUwMgBgixACwDp0YADFEiAFgHToxAGKIEAPAOnRiAMQQIQaAdejEAIghQgwA69CJARBDhBgA1iHEAIghQgwA6/hfTmptlbq7nasFwKBHiAFgndO7L8ePO1MHgCGBEAPAGh0dUldX4DYuKQGwESEGgDX8A8vo0WduAwCLEWIAWMM3HmbECGnUKHOdEAPARoQYANbwBZaRI6XMzMBtAGADQgwAa/g6MZmZhBgAMUGIAWANOjEAYowQA8AavsDi34lpbnauHgCDHiEGgDV8l5PoxACIEUIMAGsE68QQYgDYiBADwBp0YgDEGCEGgDX8OzFZWYHbAMAGhBgA1qATAyDGCDEArMGYGAAxRogBYA0muwMQY4QYANZgsjsAMUaIAWCNYJ0YJrsDYCNCDABrBOvEtLZKXq9zNQEY1AgxAKwRbGCvYUhtbc7VBGBQI8QAiJ5hBN5inZYmpaSYzxkXA8AmhBgA0Tt5Ujp1ylzPzJRcLgb3ArAdIQZA9HxdGEnKyDAfmbUXgM0IMQCi5wsqGRlS0t//WqETA8BmhBgA0fO/vdqHEAPAZoQYANHzv73ahxADwGYxCTGrV6/WpEmTlJaWpuLiYm3bti2k961bt04ul0vXXnutvQUCiE5/nRgmvANgE9tDzPr161VVVaXly5drx44dmj17tsrKytTU1NTv+z777DPdfffduuiii+wuEUC06MQAcIDtIWblypWqrKxURUWFZsyYoTVr1ig9PV1r167t8z3d3d266aab9MADD2jKlCl2lwggWv4T3fkQYgDYzNYQ09nZqfr6epWWlvaeMClJpaWlqqur6/N9Dz74oMaOHaslS5YMeI6Ojg61tLQELABizH+iOx9CDACb2Rpijh49qu7ubuXm5gZsz83NlcfjCfqerVu36je/+Y2efPLJkM5RU1OjrKysnqWgoCDqugGEiU4MAAfE1d1Jra2t+u53v6snn3xSOTk5Ib2nurpazc3NPcv+/fttrhLAGYJ1YpjsDoDNUuw8eE5OjpKTk9XY2BiwvbGxUXl5eWfs/+mnn+qzzz7T1Vdf3bPN+/dfwE1JSdHu3bs1derUgPe43W653W4bqgcQMjoxABxgaycmNTVVRUVFqq2t7dnm9XpVW1urkpKSM/afPn263nvvPTU0NPQs3/rWt3TppZeqoaGBS0VAvGKyOwAOsLUTI0lVVVVavHix5s6dq3nz5mnVqlVqa2tTRUWFJGnRokUaP368ampqlJaWppkzZwa8Pzs7W5LO2A4gjvR3izXzxACwie0hpry8XEeOHNGyZcvk8XhUWFiojRs39gz23bdvn5KS4mpoDoBw0YkB4ACXYRiG00VYqaWlRVlZWWpublam/1+oAOwzc6b0wQfSG29ICxaY2w4flvLzzR+EPHVKcrmcrRFAXIvk329aIACi118nxuuV2ttjXxOAQY8QAyB6wcbEpKebXRj/1wHAQoQYANExjOC3WLtcjIsBYCtCDIDonDhhXjKSAjsxEhPeAbAVIQZAdHwBxeWSRowIfI1ODAAbEWIARMc3qDcjo3cMjA8hBoCNCDEAohNsPIwPE94BsBEhBkB0gt1e7UMnBoCNCDEAohPs9mofQgwAGxFiAESHTgwAhxBiAESHTgwAhxBiAEQnlIG9hBgANiDEAIiO73JSsE4Mk90BsBEhBkB06MQAcAghBkB0+uvEEGIA2IgQAyA6THYHwCGEGADR4RZrAA4hxACITqi3WBtG7GoCMCQQYgBEJ5ROzKlT0smTsasJwJBAiAEQnf46MSNGSC5X4H4AYBFCDIDo9NeJSUrqDTeEGAAWI8QAiJxh9N+JkZjwDoBtCDEAItfW1jtgN1gnxn87IQaAxQgxACLnu5SUlCSlpwffh7liANiEEAMgcv6XknwDeE9HJwaATQgxACLX36BeH0IMAJsQYgBEbqBBvRIhBoBtCDEAIkcnBoCDCDEAIkcnBoCDCDEAIkcnBoCDCDEAIhdKJ4bJ7gDYhBADIHK+YEInBoADCDEAIue7nBTKmBgmuwNgMUIMgMjRiQHgIEIMgMiF04khxACwGCEGQOToxABwECEGQOTCucW6s1Pq6LC/JgBDBiEGQORCucU6I+PM/QHAAoQYAJELpROTnNwbZAgxACxEiAEQuVA6MRLjYgDYghADIDJer3T8uLneXydGYtZeALYgxACITFubZBjmeqidGCa8A2AhQgyAyPi6KsnJ0vDh/e/L5SQANiDEAIiM/0R3Llf/+xJiANiAEAMgMqFMdOdDiAFgA0IMgMiEcnu1DyEGgA0IMQAiE+rt1RIhBoAtYhJiVq9erUmTJiktLU3FxcXatm1bn/u++OKLmjt3rrKzszVixAgVFhbqd7/7XSzKBBAOOjEAHGZ7iFm/fr2qqqq0fPly7dixQ7Nnz1ZZWZmampqC7j969Gj9+Mc/Vl1dnXbt2qWKigpVVFTotddes7tUAOGgEwPAYbaHmJUrV6qyslIVFRWaMWOG1qxZo/T0dK1duzbo/vPnz9d1112n8847T1OnTtWdd96pWbNmaevWrXaXCiAc4XRimOwOgA1sDTGdnZ2qr69XaWlp7wmTklRaWqq6uroB328Yhmpra7V7925dfPHFQffp6OhQS0tLwAIgBiLpxDDZHQAL2Rpijh49qu7ubuXm5gZsz83Nlcfj6fN9zc3NysjIUGpqqq666io99thjuuyyy4LuW1NTo6ysrJ6loKDA0j8DgD5wizUAh8Xl3UkjR45UQ0OD3n33Xf3sZz9TVVWVNm/eHHTf6upqNTc39yz79++PbbHAUOU/2d1ACDEAbJBi58FzcnKUnJysxsbGgO2NjY3Ky8vr831JSUmaNm2aJKmwsFAfffSRampqNH/+/DP2dbvdcrvdltYNIAR0YgA4zNZOTGpqqoqKilRbW9uzzev1qra2ViUlJSEfx+v1qqOjw44SAUQqklusT56UOjvtqwnAkGJrJ0aSqqqqtHjxYs2dO1fz5s3TqlWr1NbWpoqKCknSokWLNH78eNXU1Egyx7jMnTtXU6dOVUdHh1555RX97ne/0+OPP253qQDCEc7AXv99Wluls86ypyYAQ4rtIaa8vFxHjhzRsmXL5PF4VFhYqI0bN/YM9t23b5+SknobQm1tbbr99tt14MABDR8+XNOnT9czzzyj8vJyu0sFEI5wOjEpKVJ6utTeboYfQgwAC7gMwzCcLsJKLS0tysrKUnNzszJD+csVQGTy86XDh6UdO6Q5cwbef9w4yeORGhqk2bNtLw9AYonk3++4vDsJQAIIpxMj9U54x1wxACxCiAEQPq9XOn7cXA9lTIzEHUoALEeIARA+X4CRQu/EEGIAWIwQAyB8viCSkiKFOk8TIQaAxQgxAMLnP9GdyxXaewgxACxGiAEQvnB+csCHEAPAYoQYAOEL5ycHfAgxACxGiAEQvnBvr/bflxADwCKEGADhC+cnB3wIMQAsRogBEL5IOjFMdgfAYoQYAOGjEwMgDhBiAISPMTEA4gAhBkD46MQAiAOEGADhoxMDIA4QYgCEL5pOTHu7dOqU9TUBGHIIMQDCF8lkd/6Bx9fJAYAoEGIAhC+Sy0mpqVJamrnOJSUAFiDEAAhfJJeTJMbFALAUIQZA+CLpxEhMeAfAUoQYAOGjEwMgDhBiAISnu9u8w0gKvxNDiAFgIUIMgPD431lEJwaAgwgxAMLjCzGpqZLbHd57CTEALESIARCeSMfDSIQYAJYixAAITyQT3fkQYgBYiBADIDyR3l7t/x5CDAALEGIAhMeKy0nMEwPAAoQYAOGhEwMgThBiAIQnmk6Mb8ZeQgwACxBiAISHTgyAOEGIARAebrEGECcIMQDCQycGQJwgxAAIjxWdmOPHzd9gAoAoEGIAhMeKToxkBhkAiAIhBkB4ounEuN3mby75HwcAIkSIARCeaH52wP99THgHIEqEGADhieZykv/76MQAiBIhBkB4ormcJDHhHQDLEGIAhIdODIA4QYgBELpTp6QTJ8z1SDsxhBgAFiHEAAidrwsjEWIAOI4QAyB0vuDhf6t0uAgxACxCiAEQumjHw/i/lxADIEqEGAChi/bOJIkQA8AyhBgAoYt2ojv/9zLZHYAoEWIAhI7LSQDiCCEGQOisuJzEZHcALBKTELN69WpNmjRJaWlpKi4u1rZt2/rc98knn9RFF12kUaNGadSoUSotLe13fwAxRCcGQByxPcSsX79eVVVVWr58uXbs2KHZs2errKxMTU1NQfffvHmzbrzxRr355puqq6tTQUGBLr/8ch08eNDuUgEMhIG9AOKI7SFm5cqVqqysVEVFhWbMmKE1a9YoPT1da9euDbr/s88+q9tvv12FhYWaPn26nnrqKXm9XtXW1tpdKoCB0IkBEEdsDTGdnZ2qr69XaWlp7wmTklRaWqq6urqQjtHe3q6uri6NHj066OsdHR1qaWkJWADYxMpOTGur5PVGXxOAIcvWEHP06FF1d3crNzc3YHtubq48Hk9Ix7j33nuVn58fEIT81dTUKCsrq2cpKCiIum4AfbCyE2MYUltb9DUBGLLi+u6kFStWaN26ddqwYYPS0tKC7lNdXa3m5uaeZf/+/TGuEhhCrOjEpKVJKSnmOnPFAIhCip0Hz8nJUXJyshobGwO2NzY2Ki8vr9/3Pvroo1qxYoXeeOMNzZo1q8/93G633G63JfUCGIAVnRiXy3z/F18wLgZAVGztxKSmpqqoqChgUK5vkG5JSUmf73v44Yf10EMPaePGjZo7d66dJQIIhxUz9vq/nxADIAq2dmIkqaqqSosXL9bcuXM1b948rVq1Sm1tbaqoqJAkLVq0SOPHj1dNTY0k6V//9V+1bNkyPffcc5o0aVLP2JmMjAxlZGTYXS6A/lhxOUliwjsAlrA9xJSXl+vIkSNatmyZPB6PCgsLtXHjxp7Bvvv27VNSUm9D6PHHH1dnZ6f+6Z/+KeA4y5cv1/333293uQD6Y8XlJP/3E2IARMH2ECNJS5cu1dKlS4O+tnnz5oDnn332mf0FAYiMVZ0YQgwAC8T13UkA4khnp9TRYa7TiQEQBwgxAELju5Qk0YkBEBcIMQBC4wsxw4f3zvMSKUIMAAsQYgCExqrxMFJviGGyOwBRIMQACI1Vdyb5H4NODIAoEGIAhMaOTgwhBkAUCDEAQmPVbL0Sk90BsAQhBkBouJwEIM4QYgCEhstJAOIMIQZAaOjEAIgzhBgAobGrE2MY0R8PwJBEiAEQGjs6MV6v1N4e/fEADEmEGAChsbITk54u+X69ngnvAESIEAMgNFZ2YlwuxsUAiBohBkBorOzESIQYAFEjxAAIjZWdGIkJ7wBEjRADIDRWztjrfxxCDIAIEWIAhIbLSQDiDCEGQGisvpxEiAEQJUIMgIF1dEidneY6nRgAcYIQA2Bgvi6MRIgBEDcIMQAG5gsa6elScrI1x/SFGCa7AxAhQgyAgVk9Hsb/WHRiAESIEANgYFbfmSQRYgBEjRADYGB0YgDEIUIMgIFZPdGdxIy9AKJGiAEwMC4nAYhDhBgAA+NyEoA4RIgBMDC7OzGGYd1xAQwZhBgAA7OzE3PqlHTihHXHBTBkEGIADMyOTsyIEZLLFXh8AAgDIQbAwOzoxCQl9YYiQgyACBBiAAzMjk6MxOBeAFEhxAAYmB2dGP/jEWIARIAQA2BgdnVimPAOQBQIMQAGRicGQBxKcboAAAnAjp8d8D9ePISYDz+UvvMdM7ANG2YuqamBjwNty86W5syRioqkgoLeu68A2IIQA6B/hjH4B/aeOCGVl0vvv2/dMceMkebONQON73H8+MQINoZhzt/T3X3mEmy7b66fkyfNx9PXB3rucklpaebidveu97f49nO7peRk8xhJSWc+Btvm/+hySV6v+Wc2jN71YNtOXzcM8zjJyVJKivnoW/yfB3vNd37f5+1/3tNr6OtR6v0znP5nCmW7/3/vYOv9veZymZ+9wwgxAPrX0WH+IyXZ14lpbrb2uOG6914zwOTmSuvWmX/pd3VJnZ2Bj8G2+b92+LBUX28e68gR6dVXzcUnN7c31PiCTX6+vX82wzA/3wMHpIMHAx996wcPSseP94YSZlCODZcrcT/rc8+VPv7Y6SoIMQAG4N8lyciw9tjx0Il5+WXpscfM9aeflubPj/6YJ05Iu3aZgWb7dvPxgw+kxkbplVfMxWfcODPMFBVJY8f2dg+Sk3vXT38e7LXOzt5AcnpQaW+P/s/kL1inIS1NGj68dxnouf82yezMRLqE0rXor8MSrDtz+vNgr0nmMfrrUvUnUQNMHCHEAOifb1BvRkbvX9xWcTrEeDxSRYW5/oMfSAsXWnPc4cOl4mJz8TlxQvrrX3tDzfbt5jicw4elP/3JXOw0erR5OWvChOCPmZn9X/7wrVv9HRjMfEEpWMA5dcp8zT+M9ncJLFjQ8p3Dfzn9cld/2/0vKfW13tdrcfI9IMQA6J9d42EkZ0OM12sGmCNHpFmzpJoae883fLj0ta+Zi097u9TQYIaanTvNwNjd3TsuIpR13/OUFPPSlC+Y+IeU/HwpPd3ePx/O5HL1hr/UVPvOMYQRYgD0z67bq/2P6USI+dWvpI0bzUsazz9vPsZaerp04YXmAiBs8dEPAhC/7OzEODXZ3V//ag7mlaSVK6UZM2J7fgCWIMQA6N9g68S0t5vzwXR2St/6lnTrrbE7NwBLEWIA9M+uie78jxnLEHP33eaA2rw86amnhvyYAiCREWIA9G8wDez9wx+kxx8313/7W3NCOgAJKyYhZvXq1Zo0aZLS0tJUXFysbdu29bnvBx98oOuvv16TJk2Sy+XSqlWrYlEigL7E4nJSZ6c534edDh2Svvc9c/2uu6TLLrP3fABsZ3uIWb9+vaqqqrR8+XLt2LFDs2fPVllZmZqamoLu397erilTpmjFihXKy8uzuzwAA7GzE+M/eZ6d3RivV1q8WPr8c6mwUPrZz+w7F4CYsT3ErFy5UpWVlaqoqNCMGTO0Zs0apaena+3atUH3/+pXv6pHHnlEN9xwg9xx8LsMwJBnZycmObk3yNgZYn7xC+mNN8y5Wp5/Pi5+8wVA9GwNMZ2dnaqvr1dpaWnvCZOSVFpaqrq6OkvO0dHRoZaWloAFgIXs7MRI9o+L2blTqq4211etkqZPt+c8AGLO1hBz9OhRdXd3Kzc3N2B7bm6uPB6PJeeoqalRVlZWz1JQUGDJcQH8nZ2dGP/j2hFi2tqkG280f5zxuuukykrrzwHAMQl/d1J1dbWam5t7lv379ztdEjC42N2JsXPCu6oqafduc9r9J5/kdmpgkLH1ZwdycnKUnJysxsbGgO2NjY2WDdp1u92MnQHslKidmA0bpCeeMIPLb38rnXWWtccH4DhbOzGpqakqKipSbW1tzzav16va2lqVlJTYeWoAVrFzsjv/41oZYg4elL7/fXP9nnukBQusOzaAuGH7D0BWVVVp8eLFmjt3rubNm6dVq1apra1NFRUVkqRFixZp/Pjxqvn7L8h2dnbqww8/7Fk/ePCgGhoalJGRoWnTptldLoDT+Toxdg/sbW625nher7RokfTFF1JRkfTQQ9YcF0DcsT3ElJeX68iRI1q2bJk8Ho8KCwu1cePGnsG++/btU1JSb0Po0KFDmjNnTs/zRx99VI8++qguueQSbd682e5yAfgzjMTrxDz6qLRpk/kL0c8+K6WmWnNcAHHH9hAjSUuXLtXSpUuDvnZ6MJk0aZIMw4hBVQAGdOKE1N1trifCLdbbt0s//rG5/qtfSeeeG/0xAcSthL87CYCNfJeSXC5pxAh7zmFliFmyRDp1Srr++t6fGAAwaBFiAPTNFywyMqQkm/66sCrEfPKJtGuXNGyYtGYNt1MDQwAhBkDf7L692v/Y0YaYl182Hy++WMrJie5YABICIQZA3+ye6E6ybrK7V14xH6+8MrrjAEgYhBgAfUuUTszx49KWLeY6IQYYMggxAPoWi06MFSFm0yaps1OaPJk7koAhhBADoG+x7MREM9md/6UkBvQCQwYhBkDf7J7ozv/YHR3mEi7D6A0xV11lXV0A4h4hBkDfYnE5yf/Yvs5PON5/X9q/X0pLk+bPt6wsAPGPEAOgb7G4nJSSYv5EgBTZuBhfF+ab35SGD7euLgBxjxADoG+x6MRI0Q3u5dZqYMgixADoWyw6Mf7HDzfEHDsmvfWWuX7FFZaWBCD+EWIA9C3eOzGvv27+QOX06dKUKdbXBSCuEWIA9C1WnZhIZ+3lriRgSCPEAOhbPHdivF7GwwBDHCEGQN9iPSYmnAnvduyQmprMX9j+xjfsqQtAXCPEAOhbLCa78z9+OJ0YXxfmssuk1FTrawIQ9wgxAIIzjN5OTDxeTuJSEjDkEWIABNfebo47keKvE3PkiLRtm7lOiAGGLEIMgOB8gSIpqXdGXbuEG2Jee83sFBUWSvn5tpUFIL4RYgAE538pye5fhg43xLz8svlIFwYY0ggxAIKL1e3VUngh5tQpsxMjEWKAIY4QAyC4WN1eLYU32d0770hffimNGiUVF9tbF4C4RogBEJwTnZhQ5onx3ZVUVmb+AjaAIYsQAyC4WHZiwrmcxE8NAPg7QgyA4GI10Z3/OU6ckLq6+t7v4EGpocEcaFxWZn9dAOIaIQZAcLGa6O70c/jOG8yrr5qP8+ZJY8bYWxOAuEeIARBcLDsxqalSWlrgeYNhll4AfggxAIKL5cBeaeBxMZ2d0uuvm+uEGAAixADoSywH9vqfp68Qs3WrdPy4lJsrXXBBbGoCENcIMQCCi7dOjO9S0hVXmD+FAGDI428CAMHFuhMz0IR3jIcBcBpCDIDgnOrEBJvwbu9e6aOPpORk6bLLYlMPgLhHiAEQXDyNifF1Yb7+dSk7Ozb1AIh7hBgAwcXTmBguJQEIghADILh46cScOCFt2mSuE2IA+CHEADiTYcRPiNm8WTp5UiookGbOjE0tABICIQbAmdrazCAjOX85yf9SkssVm1oAJARCDIAz+YJEcrI0fHhszhksxBgG42EA9IkQA+BM/oN6Y9X9CBZidu+W/t//M39b6ZvfjE0dABIGIQbAmWI9HkYKPtmdrwtzySVSRkbsagGQEAgxAM4U69urpeCT3flCzFVXxa4OAAmDEAPgTE50Yk6/nNTaKv35z+Y642EABEGIAXAmJzsxbW1Sd7dUWyt1dUnTpknnnBO7OgAkDEIMgDM52YnxnZ+7kgAMgBAD4Ey+TkwsQ4zbbd6FJJnjYggxAAZAiAFwJl8nJpaXk6Te0LR1q3TwoJSebt6ZBABBxCTErF69WpMmTVJaWpqKi4u1bdu2fvd/4YUXNH36dKWlpen888/XK77/IwMQG050YvzPt26d+bhggZSWFtsaACQM20PM+vXrVVVVpeXLl2vHjh2aPXu2ysrK1NTUFHT/v/zlL7rxxhu1ZMkS7dy5U9dee62uvfZavf/++3aXCsDHiYG9Um+Iee0185FLSQD6YXuIWblypSorK1VRUaEZM2ZozZo1Sk9P19q1a4Pu/8tf/lILFy7UPffco/POO08PPfSQLrjgAv3617+2u1QAPk4M7JV6J7zr6jIfr7gitucHkFBsDTGdnZ2qr69XaWlp7wmTklRaWqq6urqg76mrqwvYX5LKysr63L+jo0MtLS0BC4AoOd2JkaSvfEWaODG25weQUGwNMUePHlV3d7dyc3MDtufm5srj8QR9j8fjCWv/mpoaZWVl9SwFBQXWFA8MZU51YvzPx6UkAANI+LuTqqur1dzc3LPs37/f6ZKAxBcPnRhCDIABpNh58JycHCUnJ6uxsTFge2Njo/Ly8oK+Jy8vL6z93W633G63NQUDMDndicnMlL7+9dieG0DCsbUTk5qaqqKiItXW1vZs83q9qq2tVUlJSdD3lJSUBOwvSa+//nqf+wOwgVO3WI8daz6WlUnDhsX23AASjq2dGEmqqqrS4sWLNXfuXM2bN0+rVq1SW1ubKioqJEmLFi3S+PHjVVNTI0m68847dckll+jnP/+5rrrqKq1bt07bt2/XE088YXepACTJ65WOHzfXY3056eabzd9O+u53Y3teAAnJ9hBTXl6uI0eOaNmyZfJ4PCosLNTGjRt7Bu/u27dPSUm9DaELL7xQzz33nH7yk5/oRz/6kc455xz9/ve/18yZM+0uFYDUG2Ck2HdiRo+WfvrT2J4TQMJyGYZhOF2ElVpaWpSVlaXm5mZlxvovYGAwOHhQmjBBSkmROjsll8vpigAMAZH8+53wdycBsJj/eBgCDIA4RogBEMip26sBIEyEGACBnLq9GgDCRIgBEIhODIAEQYgBEIhODIAEQYgBEIhODIAEQYgBEIhODIAEQYgBEMipnxwAgDARYgD06uyU/vu/zfWzz3a2FgAYACEGQK9f/1ras0fKzZWWLHG6GgDoFyEGgOnoUenBB831n/2Mgb0A4h4hBoDp/vul5mapsND8NWkAiHOEGADShx9Ka9aY6ytXSsnJztYDACEgxACQ7rpL6u6Wrr1WuvRSp6sBgJAQYoCh7tVXpY0bpWHDpEcecboaAAgZIQYYyrq6zC6MJP3Lv0jTpjlbDwCEgRADDGVPPCF99JGUkyP95CdOVwMAYSHEAEPVl19Ky5eb6w88IGVnO1oOAISLEAMMVQ89JH3+uTRjhnTLLU5XAwBhI8QAQ9Enn5iz80rmLdUpKc7WAwARIMQAQ9E995iDeq+4Qiorc7oaAIgIIQYYajZtkl56yZzQ7uc/d7oaAIgYIQYYSrq7pR/+0Fy/7TbpvPOcrQcAokCIAYaStWulXbvMO5Huv9/pagAgKoQYYKhoaemdC2b5cumss5ytBwCiRIgBhoqaGqmpSTrnHOn2252uBgCiRogBhoK9e81bqSVzMG9qqrP1AIAFCDHAUHDvvVJnp7RggfSP/+h0NQBgCUIMMNht3Sq98IKUlGR2Y1wupysCAEsQYoDBzOuVfvADc/3735dmzXK0HACwEiEGGMyeeUaqr5dGjpQefNDpagDAUoQYYLBqa5Oqq831n/xEys11th4AsBghBhisHn5YOnRImjxZuvNOp6sBAMsRYoDB6MAB6ZFHzPWHH5bcbmfrAQAbpDhdAOJYW5vk8UiNjVJzs3mLrm/p6ur/uf+2ri7zzphhw6SUFHPxrff16L+elCSdOmUu3d2966cvfb2WlNR7zNOX5OT+X0tODvxMDKPv5329ZhiB68G29bdvf+fva9sf/yidOCFddJF0/fVnvg4AgwAhZqg5caI3mDQ29q4He2xrc7paRMPlkn7xC26pBjBoEWISwYkT0o9/LL37rvl/3V7vwI+nb+vqko4ckVpbwzt3erqUl2f+YKDbbc70OmyY+djfuv/zlJTeGk6d6n3sa/30bV6veayBuiZ9bfd6++/g9Ld0d58ZAvp73tdrLlfgerBt/e0byrlPf15aKhUVnfGfFAAGC0JMvPN4pGuukbZts+6YaWnmnSp5eX0/+tYzMqw7LwAAFiLExLP33jOniN+3Txo92hygOWqUOcbD5Qp8DLbN/7XkZCknxwwmmZlcYgAAJDxCTLx65RWpvFw6ftz81eGXXzYfAQCAJG6xjk+PPSZdfbUZYObPl95+mwADAMBpCDHx5NQpaelS6V/+xRyM+r3vSa+9Zl5KAgAAAbicFC9aWszLRxs3muNVVqyQ7rmHsSsAAPSBEBMPPvvMHMD7wQfS8OHSs89K113ndFUAAMQ1QozT3n7bvIW6qUkaN076wx+kuXOdrgoAgLjHmBgnrV9vDtxtapIKC825YAgwAACEhBDjBMOQHnpIuuEGqaPDvBPpf/9XmjDB6coAAEgYtoWYL774QjfddJMyMzOVnZ2tJUuW6Pjx4/2+54knntD8+fOVmZkpl8ulY8eO2VVe+FpapDlzpH/+Z6m6WvrNb6QtW6SDB807iULV0SEtWiQtW2Y+r6qSNmxgZlwAAMJk25iYm266SYcPH9brr7+urq4uVVRU6JZbbtFzzz3X53va29u1cOFCLVy4UNXV1XaVFplPP5UaGszldGlp0tSp0rRpgcvUqdLZZ/f+EvLRo+aA3a1bzW3/9m/SLbfE8k8BAMCg4TIMw7D6oB999JFmzJihd999V3P/PsZj48aNuvLKK3XgwAHl5+f3+/7Nmzfr0ksv1Zdffqns7Oywzt3S0qKsrCw1NzcrMzMz0j/CmZqbzUs+e/aYgWbPHnPZu9f8kcC+DBsmTZ5shpoPPzTvRMrKkl54QbrsMuvqAwAggUXy77ctnZi6ujplZ2f3BBhJKi0tVVJSkt555x1dZ+Htwx0dHero6Oh53tLSYtmxA2RlmbdBn66ry/xto9PDje95Z6f0f/9nLpIZaF5+WTrvPHvqBABgiLAlxHg8Ho0dOzbwRCkpGj16tDwej6Xnqqmp0QMPPGDpMcMybJh52Wjq1DNf6+42x8z4wk17u3TTTeYPMQIAgKiENbD3vvvuk8vl6nf5+OOP7ao1qOrqajU3N/cs+/fvj+n5+5WcbI6JufRSqbJSuvNOAgwAABYJqxNz11136eabb+53nylTpigvL09NTU0B20+dOqUvvvhCeXl5YRfZH7fbLbfbbekxAQBA/AsrxIwZM0ZjxowZcL+SkhIdO3ZM9fX1KioqkiRt2rRJXq9XxcXFkVUKAADgx5Z5Ys477zwtXLhQlZWV2rZtm9566y0tXbpUN9xwQ8+dSQcPHtT06dO1bdu2nvd5PB41NDRoz549kqT33ntPDQ0N+uKLL+woEwAAJDDbJrt79tlnNX36dC1YsEBXXnmlvvGNb+iJJ57oeb2rq0u7d+9We3t7z7Y1a9Zozpw5qqyslCRdfPHFmjNnjv7whz/YVSYAAEhQtswT4yTb5okBAAC2ieTfb347CQAAJCRCDAAASEiEGAAAkJAIMQAAICERYgAAQEIixAAAgIREiAEAAAmJEAMAABJSWL+dlAh8c/e1tLQ4XAkAAAiV79/tcObgHXQhprW1VZJUUFDgcCUAACBcra2tysrKCmnfQfezA16vV4cOHdLIkSPlcrksPXZLS4sKCgq0f/9+ftIgDHxu4eMziwyfW2T43CLD5xa+/j4zwzDU2tqq/Px8JSWFNtpl0HVikpKSNGHCBFvPkZmZyRc2Anxu4eMziwyfW2T43CLD5xa+vj6zUDswPgzsBQAACYkQAwAAEhIhJgxut1vLly+X2+12upSEwucWPj6zyPC5RYbPLTJ8buGz+jMbdAN7AQDA0EAnBgAAJCRCDAAASEiEGAAAkJAIMQAAICERYkK0evVqTZo0SWlpaSouLta2bducLimu3X///XK5XAHL9OnTnS4r7vz5z3/W1Vdfrfz8fLlcLv3+978PeN0wDC1btkzjxo3T8OHDVVpaqk8++cSZYuPIQJ/bzTfffMb3b+HChc4UGydqamr01a9+VSNHjtTYsWN17bXXavfu3QH7nDx5UnfccYfOOussZWRk6Prrr1djY6NDFceHUD63+fPnn/F9u/XWWx2qOD48/vjjmjVrVs+kdiUlJXr11Vd7Xrfqu0aICcH69etVVVWl5cuXa8eOHZo9e7bKysrU1NTkdGlx7Stf+YoOHz7cs2zdutXpkuJOW1ubZs+erdWrVwd9/eGHH9avfvUrrVmzRu+8845GjBihsrIynTx5MsaVxpeBPjdJWrhwYcD37/nnn49hhfFny5YtuuOOO/T222/r9ddfV1dXly6//HK1tbX17PPDH/5Qf/zjH/XCCy9oy5YtOnTokL797W87WLXzQvncJKmysjLg+/bwww87VHF8mDBhglasWKH6+npt375d3/zmN3XNNdfogw8+kGThd83AgObNm2fccccdPc+7u7uN/Px8o6amxsGq4tvy5cuN2bNnO11GQpFkbNiwoee51+s18vLyjEceeaRn27Fjxwy32208//zzDlQYn07/3AzDMBYvXmxcc801jtSTKJqamgxJxpYtWwzDML9bw4YNM1544YWefT766CNDklFXV+dUmXHn9M/NMAzjkksuMe68807nikoQo0aNMp566ilLv2t0YgbQ2dmp+vp6lZaW9mxLSkpSaWmp6urqHKws/n3yySfKz8/XlClTdNNNN2nfvn1Ol5RQ9u7dK4/HE/Ddy8rKUnFxMd+9EGzevFljx47Vueeeq9tuu02ff/650yXFlebmZknS6NGjJUn19fXq6uoK+L5Nnz5dZ599Nt83P6d/bj7PPvuscnJyNHPmTFVXV6u9vd2J8uJSd3e31q1bp7a2NpWUlFj6XRt0PwBptaNHj6q7u1u5ubkB23Nzc/Xxxx87VFX8Ky4u1tNPP61zzz1Xhw8f1gMPPKCLLrpI77//vkaOHOl0eQnB4/FIUtDvnu81BLdw4UJ9+9vf1uTJk/Xpp5/qRz/6ka644grV1dUpOTnZ6fIc5/V69YMf/EBf//rXNXPmTEnm9y01NVXZ2dkB+/J96xXsc5Ok73znO5o4caLy8/O1a9cu3Xvvvdq9e7defPFFB6t13nvvvaeSkhKdPHlSGRkZ2rBhg2bMmKGGhgbLvmuEGNjiiiuu6FmfNWuWiouLNXHiRP3nf/6nlixZ4mBlGApuuOGGnvXzzz9fs2bN0tSpU7V582YtWLDAwcriwx133KH333+fcWph6utzu+WWW3rWzz//fI0bN04LFizQp59+qqlTp8a6zLhx7rnnqqGhQc3Nzfqv//ovLV68WFu2bLH0HFxOGkBOTo6Sk5PPGDXd2NiovLw8h6pKPNnZ2fqHf/gH7dmzx+lSEobv+8V3L3pTpkxRTk4O3z9JS5cu1Z/+9Ce9+eabmjBhQs/2vLw8dXZ26tixYwH7830z9fW5BVNcXCxJQ/77lpqaqmnTpqmoqEg1NTWaPXu2fvnLX1r6XSPEDCA1NVVFRUWqra3t2eb1elVbW6uSkhIHK0ssx48f16effqpx48Y5XUrCmDx5svLy8gK+ey0tLXrnnXf47oXpwIED+vzzz4f0988wDC1dulQbNmzQpk2bNHny5IDXi4qKNGzYsIDv2+7du7Vv374h/X0b6HMLpqGhQZKG9PctGK/Xq46ODmu/a9aOPR6c1q1bZ7jdbuPpp582PvzwQ+OWW24xsrOzDY/H43Rpceuuu+4yNm/ebOzdu9d46623jNLSUiMnJ8doampyurS40traauzcudPYuXOnIclYuXKlsXPnTuNvf/ubYRiGsWLFCiM7O9t46aWXjF27dhnXXHONMXnyZOPEiRMOV+6s/j631tZW4+677zbq6uqMvXv3Gm+88YZxwQUXGOecc45x8uRJp0t3zG233WZkZWUZmzdvNg4fPtyztLe39+xz6623GmeffbaxadMmY/v27UZJSYlRUlLiYNXOG+hz27Nnj/Hggw8a27dvN/bu3Wu89NJLxpQpU4yLL77Y4cqddd999xlbtmwx9u7da+zatcu47777DJfLZfzP//yPYRjWfdcIMSF67LHHjLPPPttITU015s2bZ7z99ttOlxTXysvLjXHjxhmpqanG+PHjjfLycmPPnj1OlxV33nzzTUPSGcvixYsNwzBvs/7pT39q5ObmGm6321iwYIGxe/duZ4uOA/19bu3t7cbll19ujBkzxhg2bJgxceJEo7Kycsj/T0ewz0uS8R//8R89+5w4ccK4/fbbjVGjRhnp6enGddddZxw+fNi5ouPAQJ/bvn37jIsvvtgYPXq04Xa7jWnTphn33HOP0dzc7GzhDvve975nTJw40UhNTTXGjBljLFiwoCfAGIZ13zWXYRhGhJ0hAAAAxzAmBgAAJCRCDAAASEiEGAAAkJAIMQAAICERYgAAQEIixAAAgIREiAEAAAmJEAMAABISIQYAACQkQgwAAEhIhBgAAJCQCDEAACAh/X9gDQYr3IARwQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.model_selection as sk\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Input\n",
    "import tensorflow.keras.backend as kb\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import random\n",
    "\n",
    "################################################GONNA SWITCH FROM -1,0,1 to 0,1,2\n",
    "#gonna work in radians\n",
    "\n",
    "################### GLOBAL VARIABLES\n",
    "\n",
    "NUMANGLES = 50 #how many orientations each side can take\n",
    "MAXPROB = .9\n",
    "\n",
    "\n",
    "ANGLEMAX = np.pi/2\n",
    "ANGLEMIN = -np.pi/2\n",
    "\n",
    "LEFTCHOICEVAL = -1  #Value output when choosing left bar\n",
    "RIGHTCHOICEVAL = 1 #Value output when choosing right bar\n",
    "\n",
    "UNITS = 256 # Number of neurons in the dense layer\n",
    "OUTPUT_SIZE = 1 # Number of output states\n",
    "\n",
    "STIMULUSDURATION = 1.5 #length of the stimulus (seconds)\n",
    "PRESTIMULUSDURATION = 1 #length of the pre stimulus (seconds)\n",
    "\n",
    "FRAMERATE = 12 #(hz)\n",
    "\n",
    "TOTALFRAMES = int(FRAMERATE*(STIMULUSDURATION + PRESTIMULUSDURATION)) #total number of frames\n",
    "\n",
    "LASTFRAME = TOTALFRAMES - 1\n",
    "\n",
    "PRESTIMULUSFRAME = int(PRESTIMULUSDURATION * FRAMERATE - 1)\n",
    "\n",
    "#################################################3\n",
    "\n",
    "\n",
    "angleList = np.linspace(ANGLEMAX, ANGLEMIN, NUMANGLES)\n",
    "\n",
    "def difficulty(angle1, angle2):\n",
    "    sameSign = True\n",
    "    difference = abs( abs(angle1) - abs(angle2) )\n",
    "\n",
    "    if abs(angle1 + angle2) < abs(angle1)+abs(angle2): #if they are opposite sign\n",
    "        sameSign = False\n",
    "        \n",
    "    beta = 0.06 #slope parameter for steepness of difficulty curve (a function of angle separation)\n",
    "    alpha = .1 #Value of difficulty at angle difference of max\n",
    "\n",
    "    offset = np.arctanh( 2*alpha - 1 )/beta #shift the graph so at x = 0 f(x) is alpha\n",
    "\n",
    "    f = .4 #Parameter for the slope of the mapping of difference to input to the difficulty function\n",
    "    \n",
    "    if not sameSign: #the angles are not the same side so add a bias to the difficulty\n",
    "        y = 0.6  #parameter affecting how much f is changed when the angles are on same side or not\n",
    "        f = f - y*f\n",
    "\n",
    "    x = 1/(f*difference) #scale it so small differences are large value and big differences are small\n",
    "    dif = 1/2 * ( np.tanh( beta * (x + offset) ) + 1 )\n",
    "    return dif\n",
    "\n",
    "\n",
    "#Generate training data\n",
    "\n",
    "#list that holds the pairs [left angle, right angle]\n",
    "anglePairs = []\n",
    "\n",
    "#generate all pairs of angles\n",
    "for i in angleList:\n",
    "    for j in angleList:      #round to deal with floating point error\n",
    "        decimals = 1\n",
    "        if (round(i,decimals) != round(j,decimals)) & (-round(i,decimals) != round(j,decimals)): #we dont want any pairs that have equal verticallity (same abs(angle))\n",
    "            #add noise to the angles\n",
    "            noiseScale = 10 #scales how noise the angles are\n",
    "            i += np.random.randn()/noiseScale\n",
    "            j += np.random.randn()/noiseScale\n",
    "            anglePairs.append([i,j])\n",
    "\n",
    "\n",
    "#make the list a np array \n",
    "angPair = np.zeros((len(anglePairs), 2))\n",
    "counter = 0\n",
    "for i in anglePairs:\n",
    "    angPair[counter][0] = i[0]\n",
    "    angPair[counter][1] = i[1]\n",
    "    counter +=1\n",
    "anglePairs = angPair\n",
    "\n",
    "np.random.shuffle(anglePairs)\n",
    "\n",
    "\n",
    "def correctChoice(angle1, angle2):\n",
    "    '''input 2 angles return the smaller angle corresponding to more vertical orientation\n",
    "       Angle 1 is left angle 2 is right. Returns -1 for Left 1 for right\n",
    "       if they are equal error is thrown because currently only training on non equal angles\n",
    "    '''\n",
    "    global LEFTCHOICEVAL, RIGHTCHOICEVAL\n",
    "    if angle1 < angle2:\n",
    "        return LEFTCHOICEVAL        #The left bar is oriented more vertically\n",
    "    elif angle2 < angle1:\n",
    "        return RIGHTCHOICEVAL        #The right bar is oriented more vertically\n",
    "    else:\n",
    "        return \"Error. Not expecting equal angles\" #throw error if angles are equal\n",
    "\n",
    "\n",
    "def trainedChoice(angle1, angle2):\n",
    "    '''Input two angles returns the choice the mouse makes'''\n",
    "    global MAXPROB, LEFTCHOICEVAL, RIGHTCHOICEVAL\n",
    "\n",
    "    pCorrect = probablilityCorrect(difficulty(angle1, angle2))\n",
    "\n",
    "    if pCorrect > MAXPROB:\n",
    "        pCorrect = MAXPROB\n",
    "\n",
    "    cor = correctChoice(angle1,angle2)\n",
    "\n",
    "    n = np.random.random()\n",
    "\n",
    "    if n <= pCorrect: #if they are certain\n",
    "        return cor\n",
    "    else:\n",
    "          #if not certain then it is a guess\n",
    "        g = np.random.rand()\n",
    "        if g < .5:\n",
    "            return cor\n",
    "        else:\n",
    "            if cor == RIGHTCHOICEVAL:\n",
    "                return LEFTCHOICEVAL\n",
    "            else:\n",
    "                return RIGHTCHOICEVAL\n",
    "            \n",
    "def probablilityCorrect(difficulty):\n",
    "    p = -0.5*difficulty + 1\n",
    "    return p\n",
    "\n",
    "\n",
    "    \n",
    "numberTrials = len(anglePairs)\n",
    "\n",
    "#create the lists of trained and correct choices\n",
    "corCh = np.zeros(numberTrials) #List of correct choices\n",
    "trainedCh = np.zeros(numberTrials) #List of trained choices\n",
    "\n",
    "counter = 0\n",
    "for i in anglePairs:\n",
    "    angle1 = i[0]\n",
    "    angle2 = i[1]\n",
    "    corCh[counter] = correctChoice(angle1, angle2)\n",
    "    trainedCh[counter] = trainedChoice(angle1, angle2)\n",
    "    counter += 1\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trialsData = np.zeros((numberTrials, TOTALFRAMES, 2)).astype(np.float32) #stores the trials time series'\n",
    "\n",
    "responseData = np.full((numberTrials, TOTALFRAMES), np.nan) #stores the response time series\n",
    "\n",
    "\n",
    "def genRandAngs():\n",
    "        #generate 2 random angles in [-90 deg, 90 deg]\n",
    "        ang1 = np.random.random()\n",
    "        ang1 = ang1 * np.pi/2\n",
    "        swap = np.random.random()\n",
    "        if swap > .5:\n",
    "            ang1 = -ang1\n",
    "        ang2 = np.random.random()\n",
    "        ang2 = ang2 * np.pi/2\n",
    "        swap = np.random.random()\n",
    "        if swap > .5:\n",
    "            ang2 = -ang2\n",
    "        return ang1, ang2\n",
    "\n",
    "for iteration in range(numberTrials): #for each experiment create a time series\n",
    "    for frame in range(TOTALFRAMES): \n",
    "        if frame <= PRESTIMULUSFRAME: #startwith noise in range [-90 deg, 90 deg] when no stimulus present\n",
    "            trialsData[iteration][frame][0] = 0\n",
    "            trialsData[iteration][frame][1] = 0\n",
    "            if frame == PRESTIMULUSFRAME: #frame before stimulus\n",
    "                u = np.random.random()\n",
    "                if u < .5:\n",
    "                    responseData[iteration][frame] = LEFTCHOICEVAL\n",
    "                else:\n",
    "                    responseData[iteration][frame] = RIGHTCHOICEVAL\n",
    "        else:\n",
    "            #use the angles corresponding to stimulus\n",
    "            trialsData[iteration][frame][0] = anglePairs[iteration][0]\n",
    "            trialsData[iteration][frame][1] = anglePairs[iteration][1]\n",
    "            if frame == LASTFRAME   :#last frame\n",
    "                responseData[iteration][frame] = trainedCh[iteration]\n",
    "                \n",
    "            \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = sk.train_test_split(trialsData, \n",
    "                                        responseData, \n",
    "                                        test_size=0.25, \n",
    "                                        random_state=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def custom_loss(y_actual,y_pred): \n",
    "    '''calculates the loss using the frame immediately before stimulus and last frame of time series\n",
    "       The frame before stim is to set p left and p right = 0'''\n",
    "    #l1 = kb.sparse_categorical_crossentropy(y_actual[:, PRESTIMULUSFRAME], y_pred[:, PRESTIMULUSFRAME])\n",
    "    #l2 = kb.sparse_categorical_crossentropy(y_actual[:, LASTFRAME][0], y_pred[:, LASTFRAME])\n",
    "    l1 = \n",
    "    l2 = kb.mean(kb.square(y_actual[:,LASTFRAME][0] - y_pred[:,LASTFRAME]))\n",
    "    custom_loss = l1 + l2\n",
    "    #custom_loss = l2\n",
    "    return custom_loss\n",
    "\n",
    "\n",
    "def custom_cat(y_actual,y_pred):\n",
    "    '''Checks the accuracy of the final predicted output and compares it to the desired output'''\n",
    "    #l2 = tf.keras.metrics.sparse_categorical_accuracy(y_actual[:, LASTFRAME], y_pred[:, LASTFRAME])\n",
    "    l2 = kb.mean(kb.abs(y_actual[:, LASTFRAME][0] - y_pred[:, LASTFRAME]))\n",
    "    custom_cat = l2\n",
    "    return custom_cat\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Input(shape = (xTrain.shape[1], xTrain.shape[2])))\n",
    "model.add(layers.SimpleRNN(UNITS, activation = 'relu', return_sequences = True, name = 'rnn'))\n",
    "model.add(layers.BatchNormalization(name = 'batch_norm'))\n",
    "model.add(layers.Dense(OUTPUT_SIZE, activation = 'tanh', name = 'outputprobs'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "batch_size = 660 # Trials per batch\n",
    "MAX_EPOCHS = 100 # Total epochs\n",
    "\n",
    "metrr = ['accuracy', custom_cat]\n",
    "\n",
    "model.compile(\n",
    "    loss=custom_loss,\n",
    "    #loss = \"mean_squared_error\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=metrr,\n",
    ")\n",
    "\n",
    "\n",
    "#print(xTrain.shape)\n",
    "history = model.fit(xTrain, yTrain, epochs = MAX_EPOCHS, batch_size = batch_size, verbose = True,\n",
    "   validation_data = (xTest, yTest))\n",
    "yTestPredict = model.predict(xTest)\n",
    "#print(yTestPredict.shape, \"shapers\")\n",
    "\n",
    "\n",
    "one = []\n",
    "two = []\n",
    "three = []\n",
    "\n",
    "i = np.random.randint(0,numberTrials*.25)\n",
    "for a in yTestPredict[i]:\n",
    "    one.append(a[0])\n",
    "    #two.append(a[1])\n",
    "    #three.append(a[2])\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(one, c='r')\n",
    "#plt.plot(two, c='g')\n",
    "#plt.plot(three,c='b')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
